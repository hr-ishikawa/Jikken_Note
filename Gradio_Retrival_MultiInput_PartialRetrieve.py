# Fake å®Ÿé¨“ãƒãƒ¼ãƒˆ by Noriã•ã‚“ 11-05
# ï¼“ã¤ã®å…¥åŠ›é ˜åŸŸã‚’åˆ¥ã€…ã®ã‚¯ã‚¨ãƒªã§æ¤œç´¢ã™ã‚‹
# VectorStore: å„sectionã«å¯¾ã—ã¦ sectionå˜ä½ã§ã‚¯ã‚¨ãƒª

# Gradioã§WebAppåŒ–ã™ã‚‹
# usage: "python .\Gradio_Retrival_MultiInput_Partial.py"
#        URL http://0.0.0.0:7860
#        Use Ctrl+C on console to terminate the server,

# pip install gradio          # WebAppç”¨
# pip install google-genai    # embeddingsç”¨
# pip install chromadb        # vector store, similarity searchç”¨
# pip install cohere          # Re-raniknç”¨

from pprint import pprint
import re, glob, json
import pandas as pd
pd.set_option('display.width', 150)
pd.set_option('display.max_columns', 20)

import gradio as gr
import google.genai as genai    # embeddingç”¨
import chromadb                 # Vector Storeç”¨
import cohere                   # Re-ranikingç”¨

# Geminiãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®š
GEMINI_EMBEDDING_MODEL = 'gemini-embedding-001'
#GEMINI_LLM_MODEL      = 'gemini-2.0-flash'
# Cohereãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡å®š
#COHERE_EMBEDDING_MODEL = 'embed-v4.0'
#COHERE_LLM_MODEL       = 'command-a-03-2025'
COHERE_RERANK_MODEL     = 'rerank-v3.5'

def initialize_clients():
    """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–"""

     # Geminiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
    with open('GOOGLE_API_KEY.txt', 'r') as f:  # ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ã‚’å–å¾—
        api_key = f.read().strip()
    gemini_client = genai.Client(api_key=api_key)

    # --- Chromaã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
    chroma_client = chromadb.EphemeralClient()  # ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã§ä½œæˆ

    # Cohereã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
    with open('Cohere_API_KEY.txt', 'r') as f:  # ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã‚­ãƒ¼ã‚’å–å¾—
        api_key = f.read().strip()
    co = cohere.ClientV2(api_key=api_key)

    return gemini_client, chroma_client, co

def read_notes(doc_dir='./'):
    """
    Note(json)ã®èª­ã¿è¾¼ã¿
    æˆ»ã‚Šå€¤: è¾æ›¸
            {title1:{'objective':..., 'materials':..., 'procedure':..., ... }, ...  }
    """

    # doc_dirä»¥ä¸‹ã®ã™ã¹ã¦ã® .json ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    json_files = glob.glob(f"{doc_dir}*.json")
    print(json_files)
    # ãƒ¬ã‚·ãƒ”ã‚’è¾æ›¸ã«æ ¼ç´
    notes = []
    for i, file_path in enumerate(json_files, start=1):
        with open(file_path, "r", encoding="utf-8") as f:
            in_notes = json.load(f)
            notes += in_notes
    
    #pprint(notes)
    print(f"\ndoc_dir={doc_dir}, èª­ã¿ã“ã‚“ã ãƒ¬ã‚·ãƒ”ã®æ•°: {len(notes)}")
    
    notes_dic = {}
    for i, r_dic in enumerate(notes):
        if title := r_dic.get('title', False):
            notes_dic[title] = r_dic
    #pprint(notes_dic)
    
    return notes_dic

def setup_collection(_notes_dic, _gemini_client, _chroma_client):
    """ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""

    # collectionä½œæˆ
    collection_name = 'notes'
    collection = _chroma_client.create_collection(
        name = collection_name,
        metadata={'hnsw:space': 'cosine'}  # è·é›¢ãƒ¡ãƒˆãƒªãƒƒã‚¯ = 'cosine'
    )

    titles = list(_notes_dic.keys())
    n = 30 # ä¸€åº¦ã«å‡¦ç†ã™ãƒ¬ã‚·ãƒ”æ•°ï¼ˆx sectionæ•° = ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼‰
    for i in range(0, len(titles), n): # ãƒãƒƒãƒæ¯ã«
        page_contents = []
        metadatas     = []
        ids           = []

        for j in range(i, min(i+n, len(titles))): # ãƒãƒ¼ãƒˆæ¯ã«
            title = titles[j]
            note = _notes_dic[title]
            for k, s in enumerate(['objective','materials','procedure']): # sectionæ¯ã«
                page_contents.append(f"## {s}: \n{note[s]}")
                metadatas.append({'source': title, 'section': s})
                ids.append(f"doc{j}_{k}")    # id: ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªæ–‡å­—åˆ—

        # --- Embeddingã®å–å¾— ---
        doc_embs = get_embeddings(page_contents, _gemini_client, GEMINI_EMBEDDING_MODEL)
        
        # ChromaDBã¸ä¸€æ‹¬ã§è¿½åŠ 
        collection.add(
            ids=ids,
            embeddings=doc_embs,
            documents=page_contents,
            metadatas=metadatas
        )
    print(f"DBã«è¿½åŠ ã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«æ•°: {collection.count()}")

    return collection


### å…±é€šã®Embeddingé–¢æ•° =============
def get_embeddings(texts, client, embedding_model):
    # å˜ä¸€æ–‡å­—åˆ—ã§ã‚‚ãƒªã‚¹ãƒˆã§ã‚‚å¯¾å¿œ
    if isinstance(texts, str):
        texts = [texts]
        single_input = True
    else:
        single_input = False
    
    # Embeddingå–å¾—
    response = client.models.embed_content(
        model=embedding_model,
        contents=texts
    )
    embeddings = [e.values for e in response.embeddings]
    
    # å˜ä¸€å…¥åŠ›ã®å ´åˆã¯1æ¬¡å…ƒãƒªã‚¹ãƒˆã‚’è¿”ã™
    if single_input:
        return embeddings[0]
    
    return embeddings

### Vector Store(ChromaDB)ã®sectionæ¯ã«é¡ä¼¼æ¤œç´¢(Retrive) =============
def retrieve(queries_dic, k=10): # queries_dic
    print(f"### Retrieve: query=\nã€Œ{queries_dic}ã€, k={k} ") 

    # sectionæ¯ã«ãƒ•ã‚£ãƒ«ã‚¿ã‚’ã‹ã‘ã¦Retrieve, rerank
    reranked_df = pd.DataFrame({
        'docs':   pd.Series(dtype=str),
        'source': pd.Series(dtype=str),
        'score':  pd.Series(dtype=float)
    })
    n_queries = 0
    for i, section in enumerate(['objective','materials','procedure']):
        query = queries_dic[section]
        if query == '':
            continue
        
        n_queries += 1
        # --- ã‚¯ã‚¨ãƒªã‚’embedding ---
        query_emb = get_embeddings(query, gemini_client, GEMINI_EMBEDDING_MODEL)
    
        # ChromaDBã§é¡ä¼¼æ¤œç´¢ï¼ˆï¼retrievalï¼‰=======
        results = collection.query(
            query_embeddings=query_emb,
            n_results = 4*k,
            include = ['documents', 'metadatas', 'distances'],
            where = {'section': section}                        # metadataã§ã®filteræ¡ä»¶
        )
        retreaved_docs    = results['documents'][0]
        retreaved_sources = [m['source'] for m in results['metadatas'][0]]
        retreaved_dists   = results['distances'][0]
        retreaved_df = pd.DataFrame({
            'docs' :  retreaved_docs,
            'source': retreaved_sources,
            'dists':  retreaved_dists
        })
        #print(retreaved_df)
        
        # Cohereã§documentsã‚’ãƒªãƒ©ãƒ³ã‚¯(Rerank) =============
        results = co.rerank(
            model=COHERE_RERANK_MODEL,
            query=query,
            documents=retreaved_docs,
            top_n=4*k,
        ).results

        reranked_df = pd.concat(  # sectionæ¯ã®rerankã‚’é€£çµ
            [reranked_df,
             pd.DataFrame({
                'docs':   [retreaved_docs[r.index]    for r in results],
                'source': [retreaved_sources[r.index] for r in results],
                'score':  [r.relevance_score          for r in results]
            })],
            axis=0, ignore_index=True)
    aggr_reranked_df = (
        reranked_df.groupby('source', as_index=False)['score'].sum()  # sourceã§é›†ç´„, ã‚¹ã‚³ã‚¢ã¯åˆè¨ˆ
        .sort_values('score', ascending=False).reset_index(drop=True) # scoreã§ã‚½ãƒ¼ãƒˆ
    ).head(k)
    aggr_reranked_df['score'] = aggr_reranked_df['score'] / n_queries # Queryã®æ•°ã§å‰²ã‚Šæˆ»ã™

    #print(reranked_df)
    #print(aggr_reranked_df)

    return aggr_reranked_df[['source','score']].values.tolist()


# åˆæœŸè¨­å®š ==============================================
# ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå®šç¾©ã¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã€ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ

gemini_client, chroma_client, co  = initialize_clients()                   # clientã®å®šç¾©
recipes_dic = read_notes()                                                 # ãƒ¬ã‚·ãƒ”ã®èª­ã¿è¾¼ã¿
collection = setup_collection(recipes_dic, gemini_client, chroma_client)   # collectionã®ä½œæˆ


# å…¥åŠ›ç”»é¢ [Gradio ä¾å­˜éƒ¨åˆ†] ============================================================

def search_notes(input1, input2, input3, history):

    input1_clean = input1.strip()
    input2_clean = input2.strip()
    input3_clean = input3.strip()

    if not any([input1_clean, input2_clean, input3_clean]):
        history.append({
            'role': 'assistant', 'content': "âš ï¸ å…¥åŠ›ãŒç©ºã§ã™ã€‚å°‘ãªãã¨ã‚‚1ã¤å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
        })
        return history

    queries_dic = {'objective': input1_clean, 'materials': input2_clean, 'procedure': input3_clean}

    # ğŸ†• ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ ï¼ˆæ•´å½¢ç‰ˆï¼‰
    user_display = f"""
**æ¤œç´¢æ¡ä»¶:**
- ç›®çš„: {input1_clean if input1_clean else 'æŒ‡å®šãªã—'}
- è©¦è–¬: {input2_clean if input2_clean else 'æŒ‡å®šãªã—'}
- æ‰‹é †: {input3_clean if input3_clean else 'æŒ‡å®šãªã—'}
"""
    history.append({'role': 'user', 'content': user_display})  # å…¥åŠ›å†…å®¹ã®è¡¨ç¤º

    try:
        response = retrieve(queries_dic, k=10)
        # çµæœã‚’æ•´å½¢
        response_texts = '**æ¤œç´¢çµæœ:** (Rank: Title, Score)  \n' +\
            '  \n'.join([f"{i:2d}: {p}, {s:.3f}" for i, (p, s) in enumerate(response, start=1)])
    
    except Exception as e:
        response_texts = f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

    print(response_texts)
    history.append({'role': 'assistant', 'content': response_texts})  # æ¤œç´¢çµæœã®è¡¨ç¤º

    return history

def clear_inputs():
    return ['', '', '']

# Gradio UIæ§‹ç¯‰
with gr.Blocks(title="ğŸ³ ãƒ¬ã‚·ãƒ”æ¤œç´¢") as search:
    gr.Markdown("## ğŸ³ ãƒ¬ã‚·ãƒ”æ¤œç´¢")
    gr.Markdown("### æ¤œç´¢æ¡ä»¶ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    
    with gr.Row():
        with gr.Column(scale=1): # å·¦ãƒšã‚¤ãƒ³, å¹…1
            input1 = gr.Textbox(label="ç›®çš„", placeholder="ä¾‹: ã‚¿ãƒ³ãƒ‘ã‚¯è³ªã‚’æ¸¬å®šã™ã‚‹", lines=2)
            input2 = gr.Textbox(label="è©¦è–¬", placeholder="ä¾‹: BSA, ãƒ“ã‚¦ãƒ¬ãƒƒãƒˆè©¦è–¬", lines=2)
            input3 = gr.Textbox(label="æ‰‹é †", placeholder="ä¾‹: æ··åˆã—ã¦å¸å…‰åº¦ã‚’æ¸¬å®š", lines=2)
            
            with gr.Row():
                search_btn = gr.Button("ğŸ” æ¤œç´¢", variant="primary")
                clear_btn  = gr.Button("ğŸ—‘ï¸ å…¥åŠ›ã‚¯ãƒªã‚¢")
        
        with gr.Column(scale=2): # å³ãƒšã‚¤ãƒ³, å¹…3
            chatbot = gr.Chatbot(
                label="æ¤œç´¢å±¥æ­´ã¨çµæœ",
                height=600,
                show_label=True,
                type='messages'
            )
            clear_history_btn = gr.Button("ğŸ—‘ï¸ å±¥æ­´ã‚¯ãƒªã‚¢")

    # ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©
    search_btn.click(
        fn=search_notes, inputs=[input1, input2, input3, chatbot], outputs=chatbot
    )

    clear_btn.click(
        fn=clear_inputs, inputs=None, outputs=[input1, input2, input3]
    )

    clear_history_btn.click(
        fn=lambda: [], inputs=None, outputs=chatbot
    )

# ã‚¢ãƒ—ãƒªèµ·å‹•
if __name__ == "__main__":
    search.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        inbrowser=True
    )